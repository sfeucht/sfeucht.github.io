<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sheridan Feucht</title>
    <link>http://localhost:1313/</link>
    <description>Sheridan Feucht</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Feb 2019 00:00:00 +0000</lastBuildDate>
    
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Written in Go, Hugo is an open source static site generator available under the &lt;a href=&#34;https://github.com/gohugoio/hugo/blob/master/LICENSE&#34;&gt;Apache License 2.0.&lt;/a&gt; Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.&lt;/p&gt;
&lt;p&gt;Hugo makes use of a variety of open source projects including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yuin/goldmark&#34;&gt;https://github.com/yuin/goldmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alecthomas/chroma&#34;&gt;https://github.com/alecthomas/chroma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/muesli/smartcrop&#34;&gt;https://github.com/muesli/smartcrop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cobra&#34;&gt;https://github.com/spf13/cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.&lt;/p&gt;
&lt;p&gt;Hugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.&lt;/p&gt;
&lt;p&gt;Websites built with Hugo are extremely fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.&lt;/p&gt;
&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/blog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/blog/</guid>
      <description>&lt;h1 id=&#34;sheridans-blog&#34; &gt;Sheridan&amp;rsquo;s Blog
&lt;span&gt;
    &lt;a href=&#34;#sheridans-blog&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;&lt;a href=&#34;http://localhost:1313/rerereading&#34;&gt;Is AI Writing Still Nonsense?&lt;/a&gt; &lt;br&gt;
December 4, 2025 • &lt;span style=&#34;color:gray&#34;&gt;&lt;i&gt;Or, what exactly are we doing when we read LLM-generated text?&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://localhost:1313/syllogisms&#34;&gt;Solving Syllogisms is Not Intelligence&lt;/a&gt; &lt;br&gt;
April 24, 2025 • &lt;span style=&#34;color:gray&#34;&gt;&lt;i&gt;I think that we overvalue logical reasoning when it comes to measuring &amp;ldquo;intelligence.&amp;quot;&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sfeucht.github.io/rereading&#34;&gt;Writing That&amp;rsquo;s Not Language (Yet)&lt;/a&gt; &lt;br&gt;
August 10, 2021 • &lt;span style=&#34;color:gray&#34;&gt;&lt;i&gt;An interactive essay I wrote for an undergraduate seminar on the theory and practice of writing.&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/books2024/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/books2024/</guid>
      <description>&lt;h1 id=&#34;books-i-read-in-2024&#34; &gt;Books I Read in 2024
&lt;span&gt;
    &lt;a href=&#34;#books-i-read-in-2024&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;Here are the books that I remember reading this year. I don&amp;rsquo;t set reading goals for myself, but this year a lot of interesting books fell into my lap. I even managed to have time to read many of them!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;East, West - Salman Rushdie&lt;/li&gt;
&lt;li&gt;If This Is a Man - Primo Levi&lt;/li&gt;
&lt;li&gt;How to Do Things with Words - JL Austin&lt;/li&gt;
&lt;li&gt;Lolita - Vladimir Nabokov&lt;/li&gt;
&lt;li&gt;Seeing Further - Esther Kinsky&lt;/li&gt;
&lt;li&gt;The Empusium - Olga Tokarczuk&lt;/li&gt;
&lt;li&gt;Childish Literature - Alejandro Zambra&lt;/li&gt;
&lt;li&gt;The Ways of Paradise - Peter Cornell&lt;/li&gt;
&lt;li&gt;Attached - Amir Levine and Rachel S. F. Heller&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ### East, West - Salman Rushdie.

My partner Adrian bought this from a bin in Harvard Square. I found it delightful, and will be looking for more Salman Rushdie in the future. 

**If This Is a Man - Primo Levi.** Lent to me by my friend Raj. 

**How to do things with words - JL Austin.** Lent to me by my advisor David. Makes me want to read Judith Butler. 

**Lolita - Nabokov.** One of the best novels I&#39;ve read so far, ever. 

**Seeing Further - Esther Kinsky.** Gift from my partner (first book from a Fitzcarraldo Editions subscription). 

**The Empusium - Olga Tokarczuk.** 

**Childish Literature - Alejandro Zambra.**

**The Ways of Paradise - Peter Cornell.**

**Attached - Amir Levine and Rachel S. F. Heller.**  --&gt;
&lt;h2 id=&#34;unfinished&#34; &gt;Unfinished
&lt;span&gt;
    &lt;a href=&#34;#unfinished&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Here are some books I enjoyed this year but didn&amp;rsquo;t finish. I&amp;rsquo;m hoping to pick at least a few of them back up next year.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Art of Dramatic Writing - Lajos Egri&lt;/li&gt;
&lt;li&gt;3 Shades of Blue: Miles Davis, John Coltrane, Bill Evans, and the Lost Empire of Cool - James Kaplan&lt;/li&gt;
&lt;li&gt;The Enigma of Reason - Dan Sperber and Hugo Mercier&lt;/li&gt;
&lt;li&gt;Psychology and the East - Carl Jung&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/books2025/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/books2025/</guid>
      <description>&lt;h1 id=&#34;books-i-read-in-2025&#34; &gt;Books I Read in 2025
&lt;span&gt;
    &lt;a href=&#34;#books-i-read-in-2025&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;(Jan) Love in the Time of Cholera - Gabriel García Márquez&lt;/li&gt;
&lt;li&gt;(Jan) Morning and Evening - Jon Fosse&lt;/li&gt;
&lt;li&gt;(March) Pale Fire - Vladimir Nabokov&lt;/li&gt;
&lt;li&gt;(April) Orality and Literacy - Walter Ong&lt;/li&gt;
&lt;li&gt;(May) Syntactic Structures - Noam Chomsky&lt;/li&gt;
&lt;li&gt;(June) How to Write About Contemporary Art - Gilda Williams&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/fav-paintings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/fav-paintings/</guid>
      <description>&lt;h1 id=&#34;favourite-paintings&#34; &gt;Favourite Paintings
&lt;span&gt;
    &lt;a href=&#34;#favourite-paintings&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/franzmarc.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;!-- &lt;img src=&#34;http://localhost:1313/franzmarc.png&#34; alt=&#34;Grazing Horses IV - Franz Marc (1911)&#34; width=&#34;300&#34; align=&#34;left&#34;/&gt; --&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/headphones/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/headphones/</guid>
      <description>&lt;h1&gt;Dan&#39;s Headphones&lt;/h1&gt;
&lt;p&gt;A meandering list of tunes and tracks that I enjoy, updated ~monthly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[11/2023] &lt;a href=&#34;https://www.youtube.com/watch?v=G2RFKpPZcow&#34;&gt;Hallucinations - Keith Jarrett Trio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[02/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=svoGEnDX95c&#34;&gt;Invitation - Joe Henderson&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[03/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=K63CD2pwjD0&#34;&gt;Wednesday Morning, 3 A.M. - Simon &amp;amp; Garfunkel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[04/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=8NjUxjsnKgo&#34;&gt;Up Jumped Spring - Christian McBride Big Band&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[05/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=EwS0ccjya_I&#34;&gt;Stretto From The Ghetto - Branford Marsalis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[06/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=0E5l2GHBxB8&#34;&gt;Stal - C418&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[07/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=Hvz0TOm0zgI&#34;&gt;Only A Fool Would Say That - Steely Dan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[07/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=tnV7dTXlXxs&#34;&gt;Ventura Highway - America&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[08/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=t4ywIPrewpg&#34;&gt;Out on the Weekend - Neil Young&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[09/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=7ci7oJIkP2Q&#34;&gt;Tangerine - Christian McBride Live Session&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[10/2024] &lt;a href=&#34;https://www.youtube.com/watch?v=ABQjT6gDKu0&#34;&gt;Dissolved Girl - Massive Attack&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://www.youtube.com/watch?v=fS7XPtFTvb8&#34;&gt;Beginners Falafel - Flying Lotus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[01/2025] &lt;a href=&#34;https://www.youtube.com/watch?v=WMDWPH4oKwo&#34;&gt;Type Slowly - Pavement&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://www.youtube.com/watch?v=K14qg9E9SoE&#34;&gt;Slowly Typed - Pavement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[02/2025] &lt;a href=&#34;https://www.youtube.com/watch?v=9KE_I6d5m9E&#34;&gt;Armando&amp;rsquo;s Rhumba - Chick Corea&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[04/2025] &lt;a href=&#34;https://www.youtube.com/watch?v=wiLIV3H0q-Y&#34;&gt;Can&amp;rsquo;t We Be Friends - Ella &amp;amp; Louis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[06/2025] &lt;a href=&#34;https://www.youtube.com/watch?v=Claf8E18eLs&#34;&gt;You&amp;rsquo;re Gonna Make Me Lonesome When You Go - Bob Dylan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[07/2025] &lt;a href=&#34;https://www.youtube.com/watch?v=q4KYYRzFUzE&#34;&gt;Vampire in the Corner - Magdalena Bay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[09/2025] &lt;a href=&#34;https://www.youtube.com/watch?v=1XtUK5Boy7o&#34;&gt;Sunset - McCoy Tyner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[11/2025] &lt;a href=&#34;https://www.youtube.com/watch?v=TaKD1Vdarnw&#34;&gt;King Harvest (Has Surely Come) - The Band&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/manny/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/manny/</guid>
      <description>&lt;h1 id=&#34;man-my-first-and-last-friend&#34; &gt;Man, My First and Last Friend
&lt;span&gt;
    &lt;a href=&#34;#man-my-first-and-last-friend&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;&lt;span style=&#34;color:gray&#34;&gt; May 3, 2025 - A short story about high schoolers. Congrats if you found this page. &lt;a href=&#34;http://localhost:1313/manny.pdf&#34;&gt;PDF Version&lt;/a&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Man (Manny) is a kid in my grade. How do I explain him to you? Well, first, he was born in 2001. This means, like me, he is sixteen years old. He mains Fox. His outward temperament is soft, but his insides are littered with naval mines. He is the only person I have ever loved. Oh, and just like me, he loves &lt;code&gt;MEME&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Yes, &lt;code&gt;MEME&lt;/code&gt;—that is a good place to start. Two years ago after Labour Day, I sat beneath a window of cold autumn light. I was fourteen at the time. A muffin wrapper filled with jelly beans lay on the laminate table. The jellies reminded me of &lt;code&gt;THE BEAN MEME&lt;/code&gt;, and I needed this fact to be known.&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“They’re just putting beans anywhere now, huh?” I quipped. I heard a snort behind me and turned to see the corners of Man’s mouth lift.&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“I saw that &lt;code&gt;MEME&lt;/code&gt;,” he said with a hint of pride. His eyes were still fixed on the cup of candy.&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“It’s a &lt;code&gt;DANK&lt;/code&gt; one,” I said. He looked up, and I noticed for the first time that his irises were dark green. “I don’t think I caught your name?” &lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“Sorry, yeah, I’m Manny. Or Man, whichever is easier.” &lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“Okay. I’m Zain!” I wanted to say, &lt;em&gt;Man is easier, because that’s what you are, a huMan,&lt;/em&gt; but thankfully I was a moment too late, and the quip was lost to time.&lt;/p&gt;
&lt;p&gt;Syllabi were passed around the room, and that was the extent of my interactions with Man on the day after Labour Day. This was mainly because neither of us knew how to ask someone else about themselves. As I walked home that afternoon, the sky was clear and cold. It had been a number of hours since I’d eaten the beans; I wondered where in my body the glucose and dye had ended up.&lt;/p&gt;
&lt;p&gt;I won’t say that I have no friends, because I do have friends by most metrics. Lucas, who was my lockermate in Grade 6. Amos, a Marth main who hates math. But I don’t think that these are close friends. When Amos shaved his head for charity, I watched from the atrium windows. I’ve never been to Lucas’ house. My mom has never met either set of parents. But I never say that I have no friends, because that is graceless. I eat lunch with them most days. What else do you call the people you lunch with?&lt;/p&gt;
&lt;p&gt;That said, Manny was my first real friend. While it took years to know Amos and Lucas, it took weeks to know him. After a few lonely attempts at gathering like terms, I would turn around to show Manny a watermarked &lt;code&gt;MEME&lt;/code&gt;, at which he would chuckle to signal his understanding of its depth; a warm reprieve from polynomial limbo for us both. My eyes would slide away from the phone screen, just in time to see Man’s flit down towards his papers. I had never met someone else who knew about &lt;code&gt;THE BEAN MEME&lt;/code&gt;. That was the difference between him and Marina, my previous deskmate and Grade 8 crush. &lt;em&gt;Marina never understood dank,&lt;/em&gt; I would reflect quietly. &lt;em&gt;Not like Manny does. Girls typically do not grasp the subtle qualities of&lt;/em&gt; &lt;code&gt;EDGY HUMOUR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Yes, I could be &lt;code&gt;EDGY&lt;/code&gt; with Manny. We were two teenage boys, after all! Once, I said the word “kinky,” and it made him laugh to tears. Together, we enjoyed fake salutes and ironic hot dogs. And every time I made him laugh, I felt blood in my cheeks.&lt;/p&gt;
&lt;p&gt;Now, it’s lunchtime in mid-October. I reach over outstretched legs to get to my locker. It’s embarrassing to eat in the hallways, but I don’t know where else to go, so I sit and look at Amos’ laptop, over his shoulder. But today was a special day. Manny fluttered in and kneeled across from me, back to the cinderblock, with his black Adidas pants folded up like the wings of a magpie. He was uncharacteristically forward, but his voice was as soft as always.&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“Do you like calligraphy?” &lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;I don’t know what to say to this! I’ve never thought about calligraphy in my life. It’s old-person and gay at the same time. But&amp;hellip; “Yes?”&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;His corvid eyes sparkled. “You should come to the art room today, they’re doing a calligraphy thing!”&lt;/p&gt;
&lt;p&gt;I don’t exactly know what that means, but I stuff my Tupperware back into my bag and zip it up as we walk downstairs together&amp;ndash;just the two of us, since Amos and Lucas were not interested. Manny walks with a lilt, almost like he’s skipping down the stars. My throat felt slightly dry.&lt;/p&gt;
&lt;p&gt;The calligraphy itself was fine. You were supposed to be gentle but firm with the pen. I must have pressed too hard: I kept puncturing the white paper with my nib, scraping fibres away from the pink construction paper underneath. Manny carefully filled his paper with identical lowercase “a”s. For the first time, I sat next to him, instead of in front of him. As he carefully carved calligraphy “a”s, I reflected on his other lettering&amp;hellip; the way that he wrought algebraic variables, curvy-like. The sharp, blue-blue pencil that he used to point out my mistakes, as if he was carefully holding my hand as we crossed a creek. Yeah, he was smarter than me, and harder-working, but he was so soft and shy. Why did he keep practicing the letter “a”?&lt;/p&gt;
&lt;p&gt;Glancing over the other white sheafs, I noticed that his friends (girls he met through Drama who I didn’t really know) had already started writing real messages. None of them talked to me. They actually didn’t look at me at all, even when I cleared my throat. It could have been that they just loved lettering that much. Or, they were wondering what an &lt;code&gt;EDGY&lt;/code&gt; guy like me was doing in the mostly-female art room at lunch. I wasn’t autistic enough to break out the &lt;code&gt;MEMES&lt;/code&gt; in front of them, but I did spend the last ten minutes of lunch writing a number of uppercase “F”s (a subtle nod to the &lt;code&gt;PAY RESPECTS MEME&lt;/code&gt;). Manny didn’t seem to catch my reference, so we just parted with a “that was cool, see you on Thursday.”&lt;/p&gt;
&lt;p&gt;Here’s an analogy from simple machines: if all the events in my sixteen years of life were placed chronologically along a long piece of plywood and I needed to pick a location for a fulcrum, its plastic head would point to the moment when I sat down next to Manny at the calligraphy workshop. That was the first time I &lt;em&gt;smelled&lt;/em&gt; him. Green apples and clean dark hair. From that moment on, I was cursed to smell Manny’s Head and Shoulders everywhere: on the third floor, on the ground floor, in stacks of dusty textbooks, above the slush between the two sets of main doors, in my jacket and my papers, when he was at school, and especially when he was not. It was ambrosia. As an adolescent, there was of course a sexual aspect to my obsession. Manny was small, like a wren, with dark brows and ceramic hands. But he also laughed at my MEMEs, and we would play Smash together, and he would &lt;em&gt;come up&lt;/em&gt; to me at lunch. He would come up to me. He wanted to talk to me! I thought about him at night, but I also wanted to cup him in my hands. I wanted to stroke the top of his head with the backs of my fingers.&lt;/p&gt;
&lt;p&gt;This fixation spanned semesters. Weeks upon months of online quizzes and unsatisfactory porn. I figured that enough rolls of the dice (of asking “does he like me?”) would reveal his internals. Upon later reflection, my faith was not in the veracity of any one quiz, but rather in the statistical Law of Large Numbers. My sample mean was 52% YES. Throughout this process, I learned many digested facts about body language. Although Manny never touched me, he did laugh at all of my jokes, and sometimes his gaze drifted towards my mouth as I spoke. Agonizingly, this usually means that &amp;ldquo;they might like you!&amp;rdquo;&lt;/p&gt;
&lt;p&gt;But here is how I knew that he liked me for sure. On Sports Day in April, we had an extended lunch. We were in the same faction, the only two unpopular kids in our randomly-assigned group. We walked together to the gas station Tim Hortons: I got a chicken wrap, and Man got an Iced Capp. He practically fucking said it to me right then.&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“I’m so tired from today,” he began.&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“Same, I mean I don’t really ‘work out’ so like-“&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“Oh yeah, well, I kind of meant having to talk to all those random people?” Our eyes met in a flash of connection. He continued.&lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;“It’s just so hard to ‘small talk’, but it’s worse when you don’t talk at all, but everything I say&amp;hellip;” All I did was nod. To be crystal clear, there was no prompting here. &lt;br&gt;
&lt;span class=&#34;indent&#34;&gt;But then he trailed off, looked into my open eyes, and said, “But I feel so comfortable with you.”&lt;/p&gt;
&lt;p&gt;Fuck, man! It destroys me every time. I loved him, and it was so clear that he loved me too. He had to have.&lt;/p&gt;
&lt;p&gt;Now, to the worst part. When we were in Grade 10, we sat on the edge of the classroom for Math 20-1, close to the northern door. (Manny might mention that the dash one indicates the rigor of this challenging course.) Hannah was gone today, and I managed to sit with Man, alone. He seemed tired; he was darker than usual. But today was a special day, and I had to proceed with the operation. I opened the New Album on my phone, pretended to laugh at a &lt;code&gt;MEME&lt;/code&gt;, and thrusted my phone out expectantly (you know the drill, Manny). He looked up and squinted, but his face remained slack.&lt;br&gt; &lt;span class=&#34;indent&#34;&gt;“Oh, haha.” He looked back down at his lined paper, but didn’t write anything. &lt;br&gt;
What? I only had one more buffer before the big drop, and it evoked an equally tepid response. I hurriedly swiped past it and forced my hands onto the desk so as to stop them from shaking as his dark eyes jumped across the screen: the last photo in the album.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;I LIKE YOU

BOTTOM TEXT 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Manny shifted in his seat, stiff and small. “Oh,” he said, for the second time. (Maybe try using words instead of letters, Man. (I didn’t actually say that.)) I realized suddenly that I was smiling like a coyote and closed my lips. His cowlick bobbed, and he inspected the metal deskfeet, and then started to pick at his fingers. “Sorry,” he said next, which was at least a word. “I’m not, uh, I&amp;ndash;“ he finally met my eyes. “I don’t know if I really feel the same way.” His eyes slipped away in the middle of the word “same.” I knew exactly what &lt;em&gt;I&lt;/em&gt; felt in that moment. Manny, gathering his assignments and notebooks into a fabric binder, stumbled over the molded chairs and left the room.&lt;/p&gt;
&lt;p&gt;That was the last I ever saw of Manny. Well, basically. More accurately, that was that last I ever heard of him. Since that nightmarish block nine weeks ago, Manny has not said a word to me. I suppose he has made eye contact once, by accident. I made a particularly loud joke during a shared Bio 20 block, which caused his eyes to catch onto mine as our classmates crowded around the overhead projector. His eyes were still dark and full of light. I searched for hatred but found only detached curiosity, and perhaps tender pity. What a fucking joke.&lt;/p&gt;
&lt;p&gt;So, maybe that explains Manny to you. According to the field of psychology, repeated, short interactions between individuals can create a stronger sense of familiarity than intermittent deep conversations. I think this is what happened between us. Somehow, inside or between all of these interactions, I learned who Man was. So if you want to know something less personal, here are a couple more things. He loved the taste of MSG, but rarely ate a proper lunch. If I took the blue sleeve off his eraser, he would slip it back on without a word. He was timid, but those little movements were always swift and assured. Just like me, he is sixteen years old.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/research/</guid>
      <description>&lt;style&gt;
    #papers {
        list-style: none;
        padding: 0;
        counter-reset: item;
    }
    
    .paper {
        /* background-color: #3a3a3a; */
        border: 1px solid #676767ff;
        padding: 15px 20px;
        margin-bottom: 20px;
        border-radius: 2px;
        counter-increment: item;
        position: relative;
    }
    
    .paper:before {
        font-weight: normal;
        /* color: #e0e0e0; */
        margin-right: 10px;
        font-size: 1.2em;
    }
    
    .paper h5 {
        display: inline;
        margin: 0;
        font-size: 1.2em;
        /* color: #ffffff; */
        font-weight: normal;
    }

    .paper span {
        display: inline;
        margin: 0;
        font-size: 0.8em;
        /* color: #ffffff; */
        font-weight: normal;
    }
    
    /* .paper:hover {
        background-color: #424242;
        transition: all 0.2s ease;
    } */
&lt;/style&gt;
&lt;h1&gt;Selected papers&lt;/h1&gt;
&lt;p&gt;See my &lt;a href=&#34;https://scholar.google.com/citations?user=4EobJQIAAAAJ&amp;hl=en&amp;oi=sra&#34;&gt;Google Scholar&lt;/a&gt; for a full list of publications.&lt;/p&gt;
&lt;ol id=&#34;papers&#34;&gt;
    &lt;li class=&#34;paper&#34;&gt;
    &lt;a href=&#34;https://dualroute.baulab.info/&#34;&gt;&lt;h5&gt;The Dual-Route Model of Induction&lt;/h5&gt;&lt;/a&gt;&lt;br&gt;
    &lt;span&gt;&lt;b&gt;Sheridan Feucht&lt;/b&gt;, Eric Todd, Byron Wallace, David Bau&lt;/span&gt;&lt;br&gt;
    &lt;span&gt;Second Conference on Language Modeling (COLM), 2025.&lt;/span&gt;
    &lt;/li&gt;
    &lt;li class=&#34;paper&#34;&gt;
        &lt;a href=&#34;https://footprints.baulab.info/&#34;&gt;&lt;h5&gt; Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs&lt;/h5&gt;&lt;/a&gt;&lt;br&gt;
        &lt;span&gt;&lt;b&gt;Sheridan Feucht&lt;/b&gt;, David Atkinson, Byron Wallace, David Bau&lt;/span&gt;&lt;br&gt;
        &lt;span&gt;Empirical Methods in Natural Language Processing (EMNLP), 2024.&lt;/span&gt;
    &lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Other Works&lt;/h1&gt;
&lt;ol id=&#34;papers&#34;&gt;
    &lt;li class=&#34;paper&#34;&gt;
        &lt;a href=&#34;https://arithmetic.baulab.info/&#34;&gt;&lt;h5&gt;Vector Arithmetic in Concept and Token Subspaces&lt;/h5&gt;&lt;/a&gt;&lt;br&gt;
        &lt;span&gt;&lt;b&gt;Sheridan Feucht&lt;/b&gt;, Byron Wallace, David Bau&lt;/span&gt;&lt;br&gt;
        &lt;span&gt;Mechanistic Interpretability Workshop at NeurIPS, 2025.&lt;/span&gt;
    &lt;/li&gt;
    &lt;li class=&#34;paper&#34;&gt;
        &lt;a href=&#34;https://arxiv.org/pdf/2511.05743&#34;&gt;&lt;h5&gt;In-Context Learning Without Copying&lt;/h5&gt;&lt;/a&gt;&lt;br&gt;
        &lt;span&gt;Kerem Sahin, &lt;b&gt;Sheridan Feucht&lt;/b&gt;, Adam Belfki, Jannik Brinkmann, Aaron Mueller, David Bau, Chris Wendler&lt;/span&gt;&lt;br&gt;
        &lt;span&gt;Preprint (November 2025).&lt;/span&gt;
    &lt;/li&gt;
    &lt;li class=&#34;paper&#34;&gt;
        &lt;a href=&#34;https://elm.baulab.info/&#34;&gt;&lt;h5&gt;Erasing Conceptual Knowledge from Language Models&lt;/h5&gt;&lt;/a&gt;&lt;br&gt;
        &lt;span&gt;Rohit Gandikota, &lt;b&gt;Sheridan Feucht&lt;/b&gt;, Samuel Marks, David Bau&lt;/span&gt;&lt;br&gt;
        &lt;span&gt;Conference on Neural Information Processing Systems (NeurIPS), 2025.&lt;/span&gt;
    &lt;/li&gt;
    &lt;li class=&#34;paper&#34;&gt;
        &lt;a href=&#34;https://arxiv.org/pdf/2310.09612&#34;&gt;&lt;h5&gt;Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations&lt;/h5&gt;&lt;/a&gt;&lt;br&gt;
        &lt;span&gt;Alexa R. Tartaglini*, &lt;b&gt;Sheridan Feucht*&lt;/b&gt;, Michael A. Lepori, Wai Keen Vong, Charles Lovering, Brenden M. Lake, Ellie Pavlick&lt;/span&gt;&lt;br&gt;
        &lt;span&gt;Conference on Cognitive Computational Neuroscience, 2025.&lt;/span&gt;
    &lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/syllogisms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/syllogisms/</guid>
      <description>&lt;h1 id=&#34;solving-syllogisms-is-not-intelligence&#34; &gt;Solving Syllogisms is Not Intelligence
&lt;span&gt;
    &lt;a href=&#34;#solving-syllogisms-is-not-intelligence&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;April 23, 2025&lt;/p&gt;
&lt;span style=&#34;color:gray&#34;&gt;
&lt;i&gt;I think that we overvalue logical reasoning when it comes to measuring &#34;intelligence.&#34;&lt;/i&gt;
&lt;/span&gt;
&lt;p&gt;What do we mean by &lt;em&gt;intelligence&lt;/em&gt; in the context of cognitive science and AI? One thing that often comes to mind is logical reasoning: deriving conclusions from a set of axioms and rules, or thinking through syllogisms like &lt;em&gt;&amp;ldquo;all cats are mammals, all mammals are warm-blooded, therefore all cats are warm-blooded.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Until recently, I thought of structured reasoning tasks as central to human (and by extension machine) intelligence. It seemed almost obvious that a &amp;ldquo;truly&amp;rdquo; intelligent system would encode abstract notions of, e.g., &lt;a href=&#34;https://arxiv.org/abs/2310.09612&#34;&gt;same versus different,&lt;/a&gt; and that such a system would have absolutely no trouble with syllogistic tasks. I don&amp;rsquo;t think this is an unpopular opinion: critics of LLMs assert that logical tasks are &lt;a href=&#34;https://garymarcus.substack.com/p/llms-dont-do-formal-reasoning-and&#34;&gt;essential to &amp;ldquo;true&amp;rdquo; general intelligence&lt;/a&gt;. Some go on to claim that this type of reasoning is fundamentally incompatible with probablistic next-token prediction.&lt;/p&gt;
&lt;p&gt;But I&amp;rsquo;m not sure that abstract logical reasoning is quite as fundamental to human intelligence as it seems. In his 1982 work &lt;em&gt;Orality and Literacy&lt;/em&gt;, Walter Ong references a &lt;a href=&#34;https://dl1.cuni.cz/pluginfile.php/738180/mod_resource/content/0/Luria%20-%20Cognitive-development-its-cultural-and-social-foundations.pdf&#34;&gt;book containing a series of interviews&lt;/a&gt; by A.R. Luria, a Soviet neuropsychologist who interviewed low-educated populations of peasants in the Uzbek SSR in 1931. The interviews were published over forty years later, in 1976, and are very interesting to me.&lt;/p&gt;
&lt;p&gt;Here is one of the questions Luria asked people:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;In the Far North, where there is snow, all bears are white. Novaya Zemlya is in the far north and there is always snow there. What color are the bears?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Strikingly, Luria found that illiterate respondents were very unlikely to simply respond &amp;ldquo;white&amp;rdquo; to this question. They ignored the constraints of the syllogism, and reasoned based on their own personal experiences instead. Here is an example of an exchange with a 37-year-old from a remote Kashgar village &lt;a href=&#34;https://dl1.cuni.cz/pluginfile.php/738180/mod_resource/content/0/Luria%20-%20Cognitive-development-its-cultural-and-social-foundations.pdf&#34;&gt;(Luria, 1976, pp. 109)&lt;/a&gt;, who refused to accept the premise of the question.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;In the Far North, where there is snow, all bears are white. Novaya Zemlya is in the far north and there is always snow there. What color are the bears?&lt;/strong&gt;&lt;br&gt;
&amp;ldquo;There are different sorts of bears.&amp;rdquo; &lt;br&gt;
&lt;strong&gt;(The syllogism is repeated.)&lt;/strong&gt; &lt;br&gt;
&amp;ldquo;I don&amp;rsquo;t know. I&amp;rsquo;ve seen a black bear. I&amp;rsquo;ve never seen any others&amp;hellip; each locality has its own animals: if it&amp;rsquo;s white, they will be white; if it&amp;rsquo;s yellow, they will be yellow.&amp;rdquo; &lt;br&gt;
&lt;strong&gt;But what kind of bears are there in Novaya Zemlya?&lt;/strong&gt;&lt;br&gt;
&amp;ldquo;We always speak only of what we see, we don&amp;rsquo;t talk about what we haven&amp;rsquo;t seen.&amp;quot;&lt;br&gt;
&lt;strong&gt;But what do my words imply? (The syllogism is repeated.)&lt;/strong&gt;&lt;br&gt;
&amp;ldquo;Well, it&amp;rsquo;s like this: our tsar isn&amp;rsquo;t like yours, and yours isn&amp;rsquo;t like ours. Your words can be answered only by someone who was there, and if a person wasn&amp;rsquo;t there he can&amp;rsquo;t say anything on the basis of your words.&amp;rdquo; &lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Luria presents illiterate Uzbeks with many more logical puzzles, which they also seem to reject. When shown drawings of an axe, a saw, a hatchet, and a log, and asked to choose the odd one out, a 25-year-old illiterate respondent said: &amp;ldquo;They&amp;rsquo;re all alike. The saw will saw the log and the hatchet will chop it into small pieces. If one of these has to go, I&amp;rsquo;d throw out the hatchet. It doesn&amp;rsquo;t do as good a job as a saw.&amp;rdquo; Literate respondents, on the other hand, would almost always discard the log, with the rationale that the three tools should be grouped together.&lt;/p&gt;
&lt;p&gt;Regardless of the underlying explanation for this behavior, I find these interview responses thrilling to read. There are a lot of hypotheses for why these people were so resistant to such logic-based tasks (e.g., Ong points out that people who had learned to write were more likely to entertain Luria&amp;rsquo;s syllogisms), but there is no reason to believe that regular people born in the Uzbek SSR and randomly selected for this study were any more or less &amp;ldquo;intelligent&amp;rdquo; than individuals drawn from some other population. Clearly, abstract reasoning tasks like deduction and categorization are &lt;em&gt;not&lt;/em&gt; universal across humans—and these Uzbek farmers were getting along just fine without much care for them!&lt;/p&gt;
&lt;h3 id=&#34;some-sympathy&#34; &gt;Some Sympathy
&lt;span&gt;
    &lt;a href=&#34;#some-sympathy&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h3&gt;&lt;p&gt;To go back to the bear example, it&amp;rsquo;s not that people &lt;em&gt;couldn&amp;rsquo;t conceive&lt;/em&gt; of the abstract reasoning necessary to answer this problem &amp;ldquo;correctly.&amp;rdquo; After more back-and-forth in the above conversation, another young Uzbek chimed in, who was clearly able to complete the syllogistic reasoning presented in the question.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;But on the basis of my words—in the North, where there is always snow, the bears are white, can you gather what kind of bears there are in Novaya Zemlya?&lt;/strong&gt;&lt;br&gt;
&amp;ldquo;If a man was sixty or eighty and had seen a white bear and had told about it, he could be believed, but I&amp;rsquo;ve never seen one and hence I can&amp;rsquo;t say. That&amp;rsquo;s my last word. Those who saw can tell, and those who didn&amp;rsquo;t see can&amp;rsquo;t say anything!&amp;rdquo; (At this point a young Uzbek volunteered, &amp;ldquo;From your words it means that bears there are white.&amp;rdquo;)&lt;br&gt;
&lt;strong&gt;Well, which of you is right?&lt;/strong&gt;&lt;br&gt;
&amp;ldquo;What the cock knows how to do, he does. What I know, I say, and nothing beyond that!&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Reading the transcripts of these interviews, it seems to me that these questions are just frustratingly uninteresting to the interviewed subjects, who were not used to contrived tests of formal reasoning in classroom settings. It&amp;rsquo;s not unreasonable to respond this way if you aren&amp;rsquo;t used to separating a word problem from the world that it is embedded in.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example that might make you more sympathetic to the Uzbek nomads. What valid inference can you make based on the following statements (&lt;a href=&#34;https://modeltheory.org/papers/1989suppression.pdf&#34;&gt;Byrne, 1989&lt;/a&gt;)?&lt;/p&gt;
&lt;!-- http://repo.darmajaya.ac.id/4379/1/Computational%20logic%20and%20human%20thinking%20_%20how%20to%20be%20artificially%20intelligent%20%28%20PDFDrive%20%29.pdf
https://modeltheory.org/papers/1989suppression.pdf --&gt;
&lt;blockquote&gt;
&lt;p&gt;If Amy has an essay to write, she will study late in the library.
&lt;br&gt; If the library is open, Amy will study late in the library. &lt;br&gt; Amy has an essay to write.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here you are supposed to reason logically within the confines of these three sentences, which translated into symbols, say: $P\rightarrow Q$, $M\rightarrow Q$, $P$. Operating logically, I know that I can conclude $Q$. But personally, I find it very hard to conclude that &amp;ldquo;Amy will study late in the library&amp;rdquo; without knowing whether the library is open. There is an obvious &lt;em&gt;modus ponens&lt;/em&gt; here, but I just cannot make myself believe it. Others agree: 62% of respondents in Byrne&amp;rsquo;s original study made the same &amp;ldquo;error&amp;rdquo; that I did.&lt;/p&gt;
&lt;p&gt;So—if you agree with me that we can&amp;rsquo;t conclude whether Amy will study late unless we know the closing hours of the library she plans to study at, then maybe you can understand the indignation of the 37-year-old Uzbek when asked whether bears in Novaya Zemlya are white. When situated in a real life scenario, it just doesn&amp;rsquo;t make sense to reason in this way. Suspending all external world knowledge and understanding to complete a word problem just feels inane. We are used to suspending our disbelief when it comes to classic syllogisms, but once the reasoning hits a little closer to home, a lot of us end up reacting just like Luria&amp;rsquo;s interviewees.&lt;/p&gt;
&lt;h2 id=&#34;quick-conclusion&#34; &gt;Quick Conclusion
&lt;span&gt;
    &lt;a href=&#34;#quick-conclusion&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;So, is the skill of suspending disbelief in order to activate particular logical processes, given a particular type of question, a good indicator of general intelligence? Maybe our focus on &amp;ldquo;intelligence&amp;rdquo; is myopic in and of itself. In &lt;em&gt;Orality and Literacy&lt;/em&gt;, Ong notes that people from many oral cultures do not think of individuals as being &amp;ldquo;intelligent&amp;rdquo; in general. If someone is a good navigator, they are a good navigator. If they are a dancer or storyteller, they are lauded for those abilities. Why would you need some underlying g-factor to tie all of these traits together? And in the case of IQ testing, why would shape rotation and syllogism questions be uniquely suited to measure that factor, if it even exists? Even ignoring the &lt;a href=&#34;https://en.wikipedia.org/wiki/Intelligence_quotient#IQ_testing_and_the_eugenics_movement_in_the_United_States&#34;&gt;dark history of IQ testing&lt;/a&gt;, I think that this perspective is rigid and unhelpful. There is so much more to the human mind beyond formal logic and sterile test questions; arguably, the beauty of artificial and natural thought comes from its inconsistencies, illogical leaps, and unconscious intuitions.&lt;/p&gt;
&lt;!-- Ironically, I&#39;m now suspicious of the word &#34;intelligence&#34; in AI research when it refers to these narrow abstract reasoning tasks. Not just because of pedantic nitpicking, not just because of the , but because I simply think it&#39;s a really narrow view of the human mind, which makes it unhelpful for our purposes as AI researchers. Maybe we should think bigger about what exactly we mean by *intelligence* other than pointing to these types of structured tasks, especially if our purported goal is to build intelligent systems.  --&gt;
&lt;!-- 
The word problems in this anecdote are clearly reminiscent of how we measure IQ in intelligence testing. One conclusion that you might draw from this is that if illiterate people are less good at  --&gt;
</description>
    </item>
    
    <item>
      <title>Is AI Writing Still Nonsense?</title>
      <link>http://localhost:1313/rerereading/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/rerereading/</guid>
      <description>&lt;!-- # Is AI Writing Still Nonsense? --&gt;
&lt;p&gt;December 4, 2025&lt;/p&gt;
&lt;span style=&#34;color:gray&#34;&gt;
&lt;i&gt;Or, what exactly are we doing when we read LLM-generated text?&lt;/i&gt;
&lt;/span&gt;
&lt;p&gt;Recently, a &lt;a href=&#34;https://x.com/micahgoldblum/status/1989088547777966512?s=20&#34;&gt;nonsense LLM-generated paper&lt;/a&gt; kicked up some outrage in the AI community after receiving several positive reviews at ICLR, a large deep learning conference. Although it was flagged by a third reviewer and &lt;a href=&#34;https://x.com/iclr_conf/status/1989349884227715257?s=20&#34;&gt;later rejected for violating conference guidelines&lt;/a&gt;, I found it interesting that the fake paper had made it as far as it did. I was particularly moved by this reviewer&amp;rsquo;s comments:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/review3_big.png&#34; alt=&#34;I found this paper very difficult to read and comprehend. Beginning with the abstract—which conveys almost no meaningful insight to non-expert readers—the paper remains largely opaque throughout. It introduces numerous topics without proper context or explanation, ultimately leading to the unsubstantiated claim that a &amp;ldquo;verification framework&amp;rdquo; has been established.
There are two possible explanations for this lack of clarity: (1) The paper may be written in an extremely dense and narrow style, understandable only to experts working directly in this specific subarea (which I am not), or (2) The extensive use of LLM-assisted writing tools may have resulted in text that appears technically sophisticated but lacks genuine substance or coherence.&#34;&gt;&lt;/p&gt;
&lt;p&gt;The frustration here resonated with me a lot—probably because I&amp;rsquo;d been in a very similar situation before.&lt;/p&gt;
&lt;p&gt;In 2020, I close-read approximately 118 AI-generated documents on cannabis legalization (and an equal number of human-written ones). It was a painstaking task: I needed to classify the &lt;a href=&#34;https://publikationen.sulb.uni-saarland.de/bitstream/20.500.11880/23722/1/scidok_final.pdf&#34;&gt;lexical aspectual class&lt;/a&gt; of every clause, mark coherence relations between clauses, and rate the argumentation quality of each document. But there were two things that made this difficult. First, I didn&amp;rsquo;t know which articles were human-written and which were AI-generated. Second, the AI-generated documents were extremely uncanny. Take this sentence, for example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;tt&gt;If weed’s not really a public health issue and you&amp;rsquo;re really happy about it, get an understanding about the ways in which it will be able to influence your behaviour.&lt;/tt&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Is this someone&amp;rsquo;s Reddit comment, posted without a second thought? Or is it a semi-competent language model&amp;rsquo;s attempt to imitate the surface form of an argument? I was never really sure. But the quality of my annotations depended on actually understanding what was being said here, so I spent a lot of time re-reading these kinds of sentences over and over, trying to grasp some kind of meaning from them. It felt like I was having a stroke, or like I was being gaslit by the text. But then, I&amp;rsquo;d read something like&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;tt&gt;BART police already have a &amp;ldquo;marijuana alley&amp;rdquo; where potential customers could find sprayers and pagers ready to use and find it where they&amp;rsquo;re supposed to.&lt;/tt&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and breathe a sigh of relief. I&amp;rsquo;d know that this document is nonsense—that it was generated by GPT-2, a disembodied probabilistic model that cannot smoke weed and has never been to the Bay Area. Thus, I felt safe in assuming that there was &amp;ldquo;nothing there&amp;rdquo; for me to annotate.&lt;/p&gt;
&lt;p&gt;The following summer (2021), I wrote an &lt;a href=&#34;https://sfeucht.github.io/rereading&#34;&gt;essay&lt;/a&gt; about this experience for a class. It includes some cool examples of AI-generated nonsense that has the &lt;em&gt;shape&lt;/em&gt; of a sensible argument, without the content. In that essay, I argued that the text generated by LLMs is odd in that it is not language &lt;em&gt;yet&lt;/em&gt;—not until a human is able to read and extract meaning from that text. In this way, LLM-generated text is strangely beautiful.&lt;/p&gt;
&lt;h2 id=&#34;from-nonsense-sentences-to-nonsense-papers&#34; &gt;From Nonsense Sentences to Nonsense Papers
&lt;span&gt;
    &lt;a href=&#34;#from-nonsense-sentences-to-nonsense-papers&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;LLMs are a lot better now than they were in 2020: almost every sentence that comes out of a frontier model is not only structurally coherent, but sensical in the context of the sentences that came before it. You can almost always follow the flow of an LLM-generated article from beginning to end without much difficulty. So, does that mean that these documents are just&amp;hellip; meaningful now?&lt;/p&gt;
&lt;p&gt;Maybe not. There&amp;rsquo;s no fundamental difference between what GPT-2 does and what GPT-5 does (to our knowledge). If GPT-2 gave us &lt;em&gt;sentences&lt;/em&gt; that looked correct but did not actually say anything, then maybe GPT-5 gives us entire &lt;em&gt;papers&lt;/em&gt; that look coherent but don&amp;rsquo;t actually make any sense. Here&amp;rsquo;s a screenshot I took of the culprit paper&amp;rsquo;s introduction as an example.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/intro.png&#34; alt=&#34;Deploying large language models in sensitive settings creates a need for verifiable inference: proofs that outputs were computed correctly without revealing proprietary weights or private inputs. Zero-knowledge ML (ZKML) offers this, yet current systems struggle to scale to Transformer architectures.
Existing frameworks compile networks into polynomial constraint systems; prover cost is dominated by the number of constraints (roughly linear in parameter count). Cryptographic advances (e.g., lookups, sumcheck, commitments) accelerate the protocol layer, but they do not remove the model-level redundancy intrinsic to attention—leaving many constraints structurally unnecessary.
Key idea (GaugeZKP). Exploit attention&amp;rsquo;s gauge symmetries. Many parameterizations implement the same function. We rewrite deployed weights into a canonical form (constructed per head; see §3.4) without changing the model. A one-time Proof of Gauge Equivalence (PoGE) binds deployed and canonical weights; thereafter, per-inference Proofs of Verifiable Inference (PoVI) run only on the canonical model. Because this optimization is upstream of the prover, it composes with protocol-level speedups.
Scope and guarantees. We certify exact functional equivalence (no approximation); privacy follows from the zk proof system. Attention remains quadratic in sequence length. Canonicalization relies on full-column-rank projections and numerically stable QR/SPD roots; fixed-point precision uses scale 2^16 (deterministic choices yield identical outputs across implementations).&#34;&gt;&lt;/p&gt;
&lt;p&gt;I know nothing about this area, so I&amp;rsquo;ll leave critique of the &amp;ldquo;substance&amp;rdquo; of this paper to others (if  that substance exists). But what struck me was that this introduction has all of the surface-level indicators of being cogent and well-written: plain language, italicized key terms, and even a bolded paragraph header that points you to the &lt;strong&gt;Key Idea.&lt;/strong&gt; Nonetheless, when I read it, I have no idea what problem the &amp;ldquo;authors&amp;rdquo; were trying to solve, or how their &amp;ldquo;key idea&amp;rdquo; actually helps to solve it.&lt;/p&gt;
&lt;p&gt;The way I feel reading this introduction is how I used to feel reading technical papers in undergrad, when I first started trying to get into ML research. Scanning over the text, it looks like something that should make a lot of sense to an expert somewhere, but no matter how many times I re-read any sentence, I am no closer to understanding what&amp;rsquo;s going on. It could be because I don&amp;rsquo;t know about ZKML, but I don&amp;rsquo;t think this is true. If I read the introduction of &lt;a href=&#34;https://arxiv.org/pdf/2404.16109&#34;&gt;this real paper&lt;/a&gt; on zero-knowledge proofs for LLMs, it&amp;rsquo;s like a breath of fresh air: I actually understand what ZKML is and why it&amp;rsquo;s potentially interesting, and even get a rough sense of what the authors did (even though it would take lots of work for me to truly understand it).&lt;/p&gt;
&lt;p&gt;Unfortunately, the folks who had to review this paper were subjected to worse LLM-gaslighting than I ever had to experience in my annotator days. In 2020, when I re-re-read a clause like &amp;ldquo;potential customers could find sprayers and pagers ready to use and find it where they&amp;rsquo;re supposed to,&amp;rdquo; the escape hatch was always right there (I knew it could be AI). But here, not only is the nonsensity of the text much more subtle, but the possibility that this paper was AI-generated might not have even crossed the reviewers&amp;rsquo; minds. If I was in this situation, I might have felt that old insecurity from undergrad creeping in, an uncomfortable feeling that the problem is &lt;em&gt;me&lt;/em&gt;, maybe even that I should keep my head down and not object. I can see that being a factor for why this could get past so many reviewers.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-even-is-reading&#34; &gt;What Even Is Reading?
&lt;span&gt;
    &lt;a href=&#34;#what-even-is-reading&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;This specific frustration of re-re-reading sentences to no avail isn&amp;rsquo;t new; I would guess that most people have experienced it with human-written text. I know that I can sometimes get &amp;ldquo;stuck&amp;rdquo; on sentences, reading them over and over like a broken record. For me, this mostly happens when reading technical writing, but I&amp;rsquo;ve also experienced it reading fiction, and even forum posts.&lt;/p&gt;
&lt;p&gt;Reading is usually very easy for us, and it almost happens involuntarily. Think of the Stroop effect, where it&amp;rsquo;s hard to &lt;em&gt;not&lt;/em&gt; read the content of a word when it&amp;rsquo;s flashed in front of you. When we read text that&amp;rsquo;s written by others, we understand their thoughts and intentions quite quickly, almost as if there&amp;rsquo;s a wire conducting their thoughts straight into our brains. This might be why, at least in western English-speaking cultures, we conceptualize language as a conduit for meaning. This is known as the &lt;span style=&#34;font-variant:small-caps;&#34;&gt;Conduit Metaphor&lt;/span&gt;, &lt;a href=&#34;http://www.biolinguagem.com/ling_cog_cult/reddy_1979_conduit_metaphor.pdf&#34;&gt;first described&lt;/a&gt; by linguist Michael J. Reddy in 1979, who argued that it forms the basis of how English speakers conceptualize communication and meaning.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Under the &lt;span style=&#34;font-variant:small-caps;&#34;&gt;Conduit Metaphor&lt;/span&gt;, we think of thoughts/ideas as objects in our minds that can be &amp;ldquo;transferred&amp;rdquo; to other people. There&amp;rsquo;s two ideas going on here: first, that communication is the process of transferring thoughts to other people, and second, that language is the &lt;em&gt;container&lt;/em&gt; in which we put those thoughts (&amp;ldquo;put those ideas in some other paragraph,&amp;rdquo; &amp;ldquo;her words were filled with emotion&amp;rdquo;). If you study language, you&amp;rsquo;ve probably come across this assumption stated explicitly; for example, information-theoretic modeling of language conceptualizes communication as a noisy channel, where we encode meaning into messages that are then sent along this channel.&lt;/p&gt;
&lt;p&gt;However, as Reddy points out in his original essay, this metaphor is misleading. We can never actually access or experience the mind of another person, and ideas are not objects that we can take from our minds and wire directly into other people&amp;rsquo;s brains. If we could actually do that, we wouldn&amp;rsquo;t need language at all.&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; Instead, communication is more like sending someone a recipe for a specific dish. Recipes do not inherently &amp;ldquo;contain&amp;rdquo; any food in them. Every person making a particular recipe will interpret the instructions differently, depending on their kitchen and the ingredients that they have access to in their own home; this can sometimes lead to very different outcomes. It would be nice if we could directly send our friends food (i.e., thoughts), but because we don&amp;rsquo;t have a way to establish direct brain-to-brain contact, we have to make do with recipes (i.e., language).&lt;/p&gt;
&lt;!-- Instead of thinking of reading in terms of the &lt;span style=&#34;font-variant:small-caps;&#34;&gt;Conduit Metaphor&lt;/span&gt;, where a given text &#34;contains&#34; meaning that must be unpackaged by the reader, we could think of reading as a process of *generating* meaning from some object that exists in the world.  --&gt;
&lt;!-- [recipes do not inherently contain food in them.] Under this conceptualization, the process of reading is kind of like making a recipe from a cookbook—every person making a recipe will interpret the instructions differently, depending on their kitchen and the ingredients that they have access to in their own home, leading to very different outcomes. It would be nice if we could &#34;order takeout&#34; and directly transmit ideas into other people&#39;s brains, but since that is impossible, we have to make do with recipes/language.   --&gt;
&lt;!-- In this analogy where ideas are food, the &lt;span style=&#34;font-variant:small-caps;&#34;&gt;Conduit Metaphor&lt;/span&gt; would be akin to ordering UberEats (transporting someone else&#39;s food directly into your home). But since we can&#39;t actually directly transport ideas from one head to another, we have to make do with recipes, which we all interpret differently based on our own dietary restrictions and physical ingredients on hand.  --&gt;
&lt;!-- This captures the idea that when we read a text, we don&#39;t actually have access to the meaning [^3]  --&gt;
&lt;!--  --&gt;
&lt;p&gt;Under this &amp;ldquo;recipe&amp;rdquo; metaphor, meaning is not inherently contained within a text, but &lt;em&gt;comes about&lt;/em&gt; as a result of a reader interpreting that text.&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; I like this idea because it seems to resonate with other ways in which we use the word &amp;ldquo;read.&amp;rdquo; When we read tea leaves, we are generating meaning from a random blob based on our own personal symbols and conceptual structures. You can &lt;em&gt;read&lt;/em&gt; someone&amp;rsquo;s face, or &amp;ldquo;read into&amp;rdquo; their actions, but those interpretations will always be in terms of your own personality, hopes, and anxieties. The act of reading is always interpretation, rather than extraction: when someone says, &amp;ldquo;that&amp;rsquo;s my reading of it,&amp;rdquo; they are being totally precise, because every person will read a given text slightly differently.&lt;/p&gt;
&lt;p&gt;So what is happening when we find ourselves stuck re-re-reading the same sentence? If we accept that there is never any meaning &amp;ldquo;contained&amp;rdquo; inside a text, then these moments are not &lt;em&gt;failures&lt;/em&gt; to extract some true meaning lurking inside a work, but simply moments where some symbols on a page are not triggering any ideas in our minds. This could happen for any number of reasons: reader fatigue, poor writing, intentional obfuscation, or simply a lack of relevant conceptual structure on the part of the reader (like when you try to read technical writing on an unfamiliar topic). And of course, it could happen when trying to read an artefact generated by a language model that is imitating the &lt;em&gt;form&lt;/em&gt; of a well-written argument, without any of the content. Any of these things could be responsible for making a piece of writing hard to interpret and forcing us to re-re-read.&lt;/p&gt;
&lt;!-- This re-re-reading process is how we react to not being able to interpret a piece of writing.  --&gt;
&lt;h2 id=&#34;what-makes-text-meaningful&#34; &gt;What Makes Text Meaningful?
&lt;span&gt;
    &lt;a href=&#34;#what-makes-text-meaningful&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;Under this framing, if a piece of text is meaningful to a reader, it doesn&amp;rsquo;t really matter &lt;em&gt;how&lt;/em&gt; that text came into being: whether it was human-written, AI-generated, or &lt;a href=&#34;https://arxiv.org/pdf/2308.05576&#34;&gt;formed by some ants in the dirt&lt;/a&gt;. This is starting to get into philosophical territory; since I don&amp;rsquo;t have a background in philosophy, I&amp;rsquo;ll just plainly state the issue that arises for me here.&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This &amp;ldquo;ants in the dirt&amp;rdquo; example that I linked to is from Hilary Putnam&amp;rsquo;s 1981 book, &lt;em&gt;Reason, Truth, and History.&lt;/em&gt; I learned about it from &lt;a href=&#34;https://arxiv.org/pdf/2308.05576&#34;&gt;Matthew Mandelkern and Tal Linzen&amp;rsquo;s 2024 article&lt;/a&gt;, &amp;ldquo;Do Language Models&amp;rsquo; Words Refer?&amp;rdquo;, who explain it as such:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose that, at a picnic, you observe ants wending through the sand in a surprising pattern, which closely resembles the English sentence &amp;ldquo;Peano proved that arithmetic is incomplete&amp;rdquo;. At the same time, you get a text message from Luke, who is taking a logic class. He writes, &amp;ldquo;Peano proved that arithmetic is incomplete&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Intuitively, the two cases are very different, despite involving physically similar
patterns. The ants’ patterns do not say anything; they just happen to have formed
patterns which resemble meaningful words. Of course, you can interpret the pattern,
just as you can interpret an eagle’s flight as an auspicious augur; but these are interpretations you overlay on a natural pattern, not meanings intrinsic to the patterns themselves. By contrast, Luke’s words mean something definite on their own (regardless of whether you or anyone else interprets them): namely, that Peano proved that arithmetic is incomplete. What Luke said is false: it was Gödel who proved incompleteness. But
Luke said something, whereas the ants didn’t say anything at all.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- In particular, he said something false about Peano, which means that his (use of the) word ‘Peano’ managed
to refer to Peano. --&gt;
&lt;p&gt;Because of everything we just talked about, I disagree with Mandelkern and Linzen&amp;rsquo;s argument: I don&amp;rsquo;t think that there is any real difference between the ant-spelled and human-written text, at least in terms of the meaningfulness of that text. If we apply our &amp;ldquo;recipe metaphor&amp;rdquo; to this example, then the meaning that arises in our minds when we read &amp;ldquo;Peano proved that arithmetic is incomplete&amp;rdquo; is the same for Luke&amp;rsquo;s message and for the ants in the dirt. In both scenarios, the string &amp;ldquo;Peano proved that arithmetic is incomplete&amp;rdquo; induces the exact same thought in our head (apart from non-linguistic concerns, like &amp;ldquo;why is Luke texting me this?&amp;rdquo; or &amp;ldquo;how the hell did these ants happen to spell out an entire sentence?&amp;rdquo;). But crucially, this meaning is &lt;em&gt;not&lt;/em&gt; &amp;ldquo;intrinsic to the patterns themselves&amp;rdquo;—it arises only when we &lt;em&gt;see&lt;/em&gt; and interpret those patterns. And if someone else were to see the exact same patterns, the meaning that they would derive in their heads would always be slightly different.&lt;/p&gt;
&lt;p&gt;This is what confuses me about debates on whether LLM-generated text is &amp;ldquo;truly meaningful.&amp;rdquo; If I read a sentence that causes me to have a particular thought, then I have made meaning from that sentence, and so the sentence is meaningful (to me). It used to be that LLM-generated text was hard to interpret, which meant that most of the time, it was not meaningful—unless you were a poor annotator like me, whose job it was to try very hard to interpret horrible things like &lt;a href=&#34;https://www.nytimes.com/2025/12/03/magazine/chatbot-writing-style.html&#34;&gt;&amp;ldquo;It’s all just the right amount of subtlety in male porn, and the amount of subtlety you can detect is simply astounding.&amp;quot;&lt;/a&gt; But now, LLM-generated text is so good that the majority of it is meaningful to most people almost all of the time.&lt;/p&gt;
&lt;p&gt;To me, the difference between Luke&amp;rsquo;s text and the ants&amp;rsquo; sentence is in the non-linguistic considerations that arise when reading both messages. If you really saw something written in the sand by ants, you would know that this message was not &amp;ldquo;intentional,&amp;rdquo; and would therefore put less stock in whatever idea it triggers in your mind. (Unless you were superstitious and took the message as a sign, which maybe you should; seeing that for real would be crazy.) But if you knew that a piece of text came from a person, you would probably try harder to understand it, even if it seemed strange and meaningless at first. This reminds me of a recent study on human ratings of AI poetry: Colin Fraser on Twitter made &lt;a href=&#34;https://x.com/colin_fraser/status/1861324416375722257&#34;&gt;a fascinating visualization&lt;/a&gt; of their data showing that ratings of poem quality for human-written poems are &lt;em&gt;lower&lt;/em&gt; than ratings for AI-generated poetry—unless people are told that a poem was written by a human, which gives a massive jump in perceived quality (the blue arrows below).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/poetry.jpg&#34; alt=&#34;Figure from Colin Fraser on Twitter based on data from Porter and Machery (2024). It shows that overall, human-written poetry (T.S. Eliot, Shakespeare, Dickinson, etc.) is rated much lower than AI-generated poetry, but that being told a poem is human-written heavily increases ratings of quality.&#34;&gt;&lt;/p&gt;
&lt;p&gt;It seems that participants in this study are rating poem quality based in large part on the &lt;em&gt;meaningfulness&lt;/em&gt; of the text. For example, one subject rated an AI-generated poem as human-written because it &amp;ldquo;contained a lot of human experiences.&amp;rdquo; One subject, when asked to explain why they judged &amp;ldquo;Promised Years&amp;rdquo; by Dorothea Lasky as AI-generated, said that &amp;ldquo;the poem seems like it doesn&amp;rsquo;t have a clear idea.&amp;rdquo; If this respondent was told that the poem was written by a human, I wonder whether they would be willing to spend a bit more time and effort trying to interpret what Lasky was trying to say, rather than dismissing it as AI-generated.&lt;/p&gt;
&lt;!-- Another respondent points to an AI-generated poem as &#34;contain[ing] a lot of personal experiences&#34; as evidence for why it must be human-written. --&gt;
&lt;p&gt;I think that this poetry example serves as a nice foil to the ants-in-the-sand argument, because it highlights that the perceived meaningfulness of a piece of text has a lot to do with our perceptions of where the text came from. These perceptions determine how willing we are to spend time trying to understand a work: if we believe that a piece of text is human-written, we may spend a lot more time trying to interpret and understand it.&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; So maybe this is why &amp;ldquo;Peano proved that arithmetic was incomplete&amp;rdquo; &lt;em&gt;feels&lt;/em&gt; so different coming from ants in the sand, rather than coming from a trusted friend: if we know (or think we know) that something was written by a human, it changes the way that we approach interpretation of that text.&lt;/p&gt;
&lt;h2 id=&#34;what-if-this-ai-paper-was-actually-good&#34; &gt;What if this AI Paper Was Actually Good?
&lt;span&gt;
    &lt;a href=&#34;#what-if-this-ai-paper-was-actually-good&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;There have been lots of infamous examples throughout the decades of &lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_scholarly_publishing_stings&#34;&gt;people writing hoax papers&lt;/a&gt; that have made it past peer review. What&amp;rsquo;s interesting about these cases is that theoretically, it might be possible for a hoaxer to write a paper that they believe to be nonsense, but that, when interpreted by another person in the field, actually says something profound or interesting. Now that we are apparently letting LLMs write entire papers for us, this seems even more likely to happen. Unlike the hoax papers, the AI is at least &amp;ldquo;trying&amp;rdquo; to write something good. So, what if this particular AI-written paper had actually offered a truly profound breakthrough or insight?&lt;/p&gt;
&lt;p&gt;It would be interesting if, one day, an LLM &lt;em&gt;does&lt;/em&gt; actually write a paper that says something new and profound. Maybe it would be just as opaquely written as the above ZKML paper, requiring many human augurs to spend countless hours interpreting and deriving insights from the work. Hopefully this doesn&amp;rsquo;t happen: if such a profound AI paper did exist, I doubt that anyone would bother taking the time to understand it; it would probably get lost &lt;a href=&#34;https://en.wikipedia.org/wiki/The_Library_of_Babel&#34;&gt;in a sea of nonsense papers&lt;/a&gt;. But if we &lt;em&gt;did&lt;/em&gt; take the time to read such a paper, then those novel insights wouldn&amp;rsquo;t have come from an LLM—they would have come from us, the readers.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Discussions with David Atkinson and Andy Arditi back in November inspired a lot of the ideas that ended up here. Thanks to Adrian Chang for continual feedback on drafts of this post. Plus, thank you to Si Wu for recommending the book &amp;ldquo;Metaphors We Live By&amp;rdquo; to me, and all of the above for extra comments at the end.&lt;/em&gt;&lt;/p&gt;
&lt;!-- Phil Gentry: A professor of mine went to go hear Derrida speak once. The entire talk was about cows; everyone was flummoxed but listened carefully, and took notes about...cows. There was a short break, and when Derrida came back, he was like, “I’m told it is pronounced ‘chaos.’” --&gt;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Of course, the right thing to do in this situation would always be to ask for the paper to be reassigned, or review to the best of your ability with low confidence; if a paper is that hard to understand, it probably shouldn&amp;rsquo;t get published anyway. But a willingness to call BS seems to be a combination of seniority and personality.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;I learned about this idea from George Lakoff and Mark Johnson&amp;rsquo;s book, &lt;a href=&#34;https://en.wikipedia.org/wiki/Metaphors_We_Live_By&#34;&gt;&lt;em&gt;Metaphors We Live By&lt;/em&gt;&lt;/a&gt;, published in 1980. Thank you to Si Wu for recommending this book to me!&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Maybe the world would look something like the Human Instrumentality Project from Evangelion.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Reddy&amp;rsquo;s name for this is actually the &amp;ldquo;toolmakers paradigm,&amp;rdquo; but since the way I think about it might not match his original essay exactly, I won&amp;rsquo;t use his term in this post.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;If you have a philosophy background and are interested in talking about this, please reach out! This has been bothering me a lot.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;If it is written by &lt;a href=&#34;https://x.com/pmgentry/status/1379093511539150852?s=20&#34;&gt;someone well-respected like Derrida&lt;/a&gt;, we would maybe spend even more time.&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Notes on Geometry Papers</title>
      <link>http://localhost:1313/geometry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/geometry/</guid>
      <description>&lt;h1 id=&#34;not-all-lm-features-are-1d-linear-engels-et-al-2024&#34; &gt;Not All LM Features are 1D Linear (Engels et al., 2024)
&lt;span&gt;
    &lt;a href=&#34;#not-all-lm-features-are-1d-linear-engels-et-al-2024&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/pdf/2405.14860&#34;&gt;Paper&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=eVlGeHA2Cnw&amp;amp;t=858s&#34;&gt;Video&lt;/a&gt;] - They&amp;rsquo;re basically trying to figure out how to decompose hidden states into sums of different functions of the input (features). So for example, you might have a 1-dimensional representation of an integer value 3, added to an n-dimensional representation of the language semantics of &amp;ldquo;three,&amp;rdquo; etc.&lt;/p&gt;
&lt;p&gt;When you&amp;rsquo;re doing this, there&amp;rsquo;s a problem: how do you know whether a multi-dimensional feature you&amp;rsquo;ve found is &amp;ldquo;atomic&amp;rdquo;, or whether it&amp;rsquo;s actually possible to further decompose it into other sub-features?&lt;/p&gt;
&lt;h2 id=&#34;reducibility&#34; &gt;Reducibility
&lt;span&gt;
    &lt;a href=&#34;#reducibility&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;To figure this out, they formally define &lt;em&gt;reducible&lt;/em&gt; features—which crucially we don&amp;rsquo;t actually want to count as a good/valid multi-dimensional feature. So for a given multi-dimensional feature $\bf f$ (defined as a function that maps from inputs to some $d_f$-dimensional subspace), can it actually be &amp;ldquo;broken down&amp;rdquo; (e.g. latitude and longitude)?&lt;/p&gt;
&lt;p&gt;They come up with two metrics to see if this is approximately true:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$S(f)$ - &lt;strong&gt;Separability index.&lt;/strong&gt; For all possible ways to break down a feature into $\bf a$ and $\bf b$, what is the minimum mutual information $I(\textbf{a}, \textbf{b})$? For example, a multidimensional Gaussian will not actually have mutual information between subfeatures if you choose the right axes. Higher = harder to separate.&lt;/li&gt;
&lt;li&gt;$M_\epsilon(f)$ - &lt;strong&gt;$\epsilon$-mixture index.&lt;/strong&gt; Across all the token positions, can we pick a special vector $\bf v$ for which the feature can be projected near zero pretty often? (in practice, this is something like less than $\epsilon$ * standard deviation rather than zero). If you can find a vector $\bf v$ and offset $c$ so that $\textbf{v} \cdot \textbf{f(t)} + c$ is small for lots of token positions, then that means that in all of those cases that direction in the feature space wasn&amp;rsquo;t really being used. Of course, $\bf v$ has to be within the subspace $\mathbb{R}^{d_f}$, because otherwise you could easily find a vector that&amp;rsquo;s orthogonal to $\mathbb{R}^{d_f}$ and zeros out everything. Higher = easier to separate.&lt;/li&gt;
&lt;/ol&gt;
 &lt;details&gt;
&lt;summary&gt;Concrete-ish example of mixture index&lt;/summary&gt;
Let&#39;s say your multi-dimensional feature $\bf f$ was dimension $d_f=2$ but to your dismay it was actually a mixture of two features, $\bf e_1$ and $\bf e_2$. For 60% of the token positions where the feature is active, it&#39;s using mostly $\bf e_1$, and for the other 40% it&#39;s using mostly $\bf e_2$. In such a case, you could choose $\bf v=e_2$ and get a zero dot product for 60% of tokens and one dot product for the other 40%, resulting in a score of around 0.60. This is pretty high, and it indicates that this so-called &#34;multi-dimensional feature&#34; is actually just a combination of sub-features represented by $\bf e_1$ and $\bf e_2$.
&lt;/details&gt;
&lt;p&gt;In practice, $S(f)$ scores for GPT-2 features are mostly less than 0.2 (aka, most features are pretty separable), and $M_\epsilon(f)$ features are quite high, mostly bigger than 0.4 (aka, most features are pretty much mixtures). They use these scores to argue that their day-of-week features, since they have high $S(f)$ and low $M_\epsilon(f)$, are irreducible multi-dimensional features.&lt;/p&gt;
&lt;h2 id=&#34;going-from-sae-to-multi-dim-features&#34; &gt;Going from SAE to Multi-Dim Features
&lt;span&gt;
    &lt;a href=&#34;#going-from-sae-to-multi-dim-features&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;If $\bf D$ is the decoder matrix of the SAE containing all of the output features, then to cluster features together, they take the cosine similarity between all decoder vectors and prune away cosine similarities below a threshold $T$. By construction these clusters will be &amp;ldquo;$T$-orthogonal&amp;rdquo; (i.e. if $T=0$ then they&amp;rsquo;re truly orthogonal).&lt;/p&gt;
&lt;p&gt;If the SAE is good at reconstructing, then when a multi-dimensional non-reducible feature $\bf f$ is active, &lt;strong&gt;they claim that one of these cosine-similar clusters will be equal to f.&lt;/strong&gt; This is not super obvious. Naively, you&amp;rsquo;d think it&amp;rsquo;d be the opposite—that if $\bf f$ was a 2D feature that was properly reconstructed by the SAE, the SAE would have learned two orthogonal decoder vectors that span the space (and those would have close to zero cosine similarity). But if $\bf f$ is truly a multi-dimensional feature, it would never make sense to separate out these two features; then the SAE would get penalized by always having both features active whenever it needs to reconstruct $\bf f$. So instead, they guess that the SAE would learn a bunch of cosine-similar things that are all in $\bf f$ (intuitively, maybe this would be like learning separate &amp;ldquo;Monday&amp;rdquo;, &amp;ldquo;Tuesday&amp;rdquo;, &amp;ldquo;Wednesday&amp;rdquo; features).&lt;/p&gt;
&lt;p&gt;So what they do is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cluster all the SAE decoder vectors using this thresholding thing&lt;/li&gt;
&lt;li&gt;To analyze a cluster, get cluster-specific reconstructions of all hidden states $\textbf{x}_{i,l}$.&lt;/li&gt;
&lt;li&gt;Analyze that cluster&amp;rsquo;s representations across a bunch of hidden states by looking at PCA projections, or running $S(f)$ and $M_\epsilon(f)$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Two important details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In order to calculate these scores, they actually &lt;em&gt;first&lt;/em&gt; calculate the PCA directions over the reconstructed activations, and then project onto PCA components 1-2, 2-3, 3-4, 4-5, averaging the separability/mixture over each of these planes.&lt;/li&gt;
&lt;li&gt;This process implicitly filters for datapoints that are relevant for this cluster/feature. In step (2), if none of the cluster&amp;rsquo;s features are active for a particular hidden state $\textbf{x}_{i,l}$, it is not included in the analysis. In the case of a days-of-the-week feature, the PCAs will of course look pretty nice, since the biggest variation between a bunch of weekday vectors will almost surely be information about weekday.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another cool thing is that they show that these features are actually cones, where the first principal component seems to be intensity of weekday-ness, perhaps.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/geometry/engels_pca.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;intervening-on-circles&#34; &gt;Intervening on Circles
&lt;span&gt;
    &lt;a href=&#34;#intervening-on-circles&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;p&gt;While they do try intervening on the subspace found by the SAE, they get slightly better results by training probes to find good subspaces at each layer. Specifically, they&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Take the top-$k$ principal component directions of hidden states at the &amp;ldquo;Monday&amp;rdquo; position (pretty sure this position) across all the prompts and project onto there first.&lt;/li&gt;
&lt;li&gt;Then train a linear probe $\bf P$ in that space that maps from $k$ to 2 dimensions, trained to correspond to &lt;tt&gt;circle&lt;/tt&gt;($\alpha$) &amp;ndash; e.g. for weekdays &lt;tt&gt;circle&lt;/tt&gt;$(\alpha)=[\cos(2\pi\alpha/7), \sin(2\pi\alpha/7)]$.&lt;/li&gt;
&lt;li&gt;To intervene on &amp;ldquo;Monday&amp;rdquo; and make it look like &amp;ldquo;Wednesday&amp;rdquo;, they just discard &amp;ldquo;Monday.&amp;rdquo; I am confused about how exactly this intervention works, because their Equation 6 seems wrong (you can&amp;rsquo;t calculate &lt;tt&gt;circle&lt;/tt&gt;$(\alpha_{j&amp;rsquo;}) - \overline{x_{i,l}}$ directly because they are different dimensions). Equation 7 doesn&amp;rsquo;t clarify, it seems to have a missing parenthesis.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- Start with mean over prompts $\overline{x_{i,l}}$. Project that onto the circle with $\textbf{PW}_{i,l}$ and then calculate offset from &lt;tt&gt;circle&lt;/tt&gt;(Wednesday). Then project that offset back to model space with $\textbf{W}^T\_{i,l}\textbf{P}^+$ and add back to the mean to get final activation.  --&gt;
&lt;p&gt;Josh Engels mentions in the talk that the intervention only works if you ablate out everything else that&amp;rsquo;s not in the PCA; I&amp;rsquo;m not exactly sure what he means here, probably the fact that they have to mean-ablate everything by using $\overline{x_{i,l}}$ instead of the base activation.&lt;/p&gt;
&lt;h2 id=&#34;generic-ideastakeaways&#34; &gt;Generic Ideas/Takeaways
&lt;span&gt;
    &lt;a href=&#34;#generic-ideastakeaways&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;How does the model actually use these circular representations to calculate the answer?&lt;/li&gt;
&lt;li&gt;Some of these facts must be piecewise memorized as well (e.g. Saturday is 1 day after Friday is almost surely memorized) &amp;ndash; probably why they have to ablate all other weekday information.&lt;/li&gt;
&lt;li&gt;Presumably lots of weekday embedding information is unrelated to circles &amp;ndash; if you rotated within the circle subspace for tasks like &amp;ldquo;What holidays are typically on [Thursday]?&amp;rdquo; or &amp;ldquo;What letter does [Thursday] start with?&amp;rdquo; then you&amp;rsquo;d probably see it doesn&amp;rsquo;t affect anything.&lt;/li&gt;
&lt;li&gt;It still worries me to think about multiple circles happening at once. If you have six orthogonal 2D circles, could that just be some alternate formulation of an n-dimensional subspace?&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;when-models-manipulate-manifolds--linebreaks-gurnee-et-al-2025&#34; &gt;When Models Manipulate Manifolds / Linebreaks (Gurnee et al., 2025)
&lt;span&gt;
    &lt;a href=&#34;#when-models-manipulate-manifolds--linebreaks-gurnee-et-al-2025&#34;&gt;
        &lt;svg viewBox=&#34;0 0 28 23&#34; height=&#34;100%&#34; width=&#34;19&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;path d=&#34;M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;path d=&#34;M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-miterlimit=&#34;10&#34; stroke-width=&#34;2&#34;/&gt;&lt;/svg&gt;
    &lt;/a&gt;
&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;They find 1-dimensional feature manifolds embedded in low-dimensional subspaces for: num. characters in a token, num. characters in current line, overall line width constraint, num characters &lt;em&gt;remaining&lt;/em&gt; in the current line.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It wouldn&amp;rsquo;t really make sense to dedicate an entire 1D subspace to num characters in current line, because then you&amp;rsquo;re wasting that entire dimension if you&amp;rsquo;re in a doc that doesn&amp;rsquo;t have linebreaks. This is really strong evidence for superposition; as they note, a ring structure implies that there is superposition/interference in that representation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They find a bunch of features that activate on a &lt;a href=&#34;https://transformer-circuits.pub/2025/linebreaks/index.html#char-count&#34;&gt;range of given line widths&lt;/a&gt;. Since two are usually active at a time, they imagine a curve connecting all these features. If they take PCA across 150 different line width averages for Layer 2, they find a 6-dimensional subspace that explains 95% of the variance across line width averages. They can also reconstruct the activations &lt;em&gt;only&lt;/em&gt; using the SAE features above, and the curves track each other fairly closely.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is really interesting because there is no human-intuitive reason why line widths would have to be represented as a curve, right? Unless there was something about a 60-length line that nicely parallels a 30-length line? This really might be an artifact of superposition, because we don&amp;rsquo;t want to use up an entire dimension, so we snake it around like so; probably because you&amp;rsquo;re unlikely to confuse 60 and 30 anyway(?)&lt;/li&gt;
&lt;li&gt;Q: do all of their averaged-line-width features come from tokens within documents with a max line width of 150, or do they come from different documents with different &lt;em&gt;max&lt;/em&gt; line widths?&lt;/li&gt;
&lt;li&gt;If we were trying to find this using some geometric DAS, why would we assume we&amp;rsquo;re looking for a curved manifold? Or, how would we figure out what kind of curves we might be looking for? &lt;em&gt;This seems like something someone who&amp;rsquo;s good at math could figure out&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;150-way logistic regression: basically just a bunch of model_dim vectors each individually trained to activate for e.g. a 50 char line, 51 char, etc. If they take all these guys and do PCA, the top 6 components capture 82% of the variance of these vectors. You can just plot the behavior of each of these logistic regression probes on a heatmap, and see that the diagonal is quite fuzzy. But you also see that there is some small off-diagonal &amp;ldquo;ringing&amp;rdquo; in their predictions as well (which also occurs if you take cosine sim. between all the mean vectors, or the probe vectors).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A very fuzzy intuition for this is that if you have some representation of line width that snakes around within a subspace back onto itself, as well as a logistic regression probe vector that&amp;rsquo;s trained to have a high dot product with lines of a particular length, then it wouldn&amp;rsquo;t just slightly activate for adjacent line widths but &lt;em&gt;also&lt;/em&gt; for areas near it on the spiral. (This is basically the intuition in their toy example.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Math details for their toy model: let&amp;rsquo;s say we want 150 vectors that are all somewhat similar to their neighbors but orthogonal to everything else. They define the cosine similarity matrix $X$ for this toy setting as a &amp;ldquo;circulant matrix&amp;rdquo; where basically you just have the row [1, 0.5, 0, &amp;hellip;] permuted to the right in every row to create a fuzzy diagonal. If you take a 5-rank approximation of it using the eigendecomposition of $X$, then you get the same &amp;ldquo;ringing&amp;rdquo; pattern. &lt;em&gt;Note: it is nice to just look at the cosine similarity matrix here instead of trying to think of a familiar shape in 150 or 5 dimensions.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Probably the reason why they define $X$ to be circulant is because of its connection to Fourier transforms. Multiplying by a circulant matrix implements a convolution, which is just multiplication in Fourier space; this means that &lt;a href=&#34;https://en.wikipedia.org/wiki/Circulant_matrix#Eigenvectors_and_eigenvalues&#34;&gt;circulant matrices have eigenvectors&lt;/a&gt; that are Fourier modes (i.e., fundamental waves). So this approximation they were doing is equivalent to truncating the less-important Fourier coefficients for $X$.&lt;/p&gt;
&lt;p&gt;Since this toy Fourier approximation looks so much like their real-life ringing example, they wonder whether the line width stuff in the real LLM is constructed via Fourier features. They say you can&amp;rsquo;t have just &lt;em&gt;any&lt;/em&gt; generic low-dimensional embedding of a high-dimensional circle that slides along itself via a linear transform, which I buy. In the &lt;a href=&#34;https://transformer-circuits.pub/2025/linebreaks/index.html#appendix-gibbs&#34;&gt;footnote&lt;/a&gt; TODO explain based on my notebook. TODO look at their experiments.&lt;/p&gt;
 &lt;!-- but then say that a &#34;Fourier construction&#34; could have this property. [Point of confusion: I thought that you could use a Fourier series to approximate any function...?] --&gt;</description>
    </item>
    
  </channel>
</rss>
